{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74e1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flops计算法官法\n",
    "# 常规卷积  input:（Di,Di,M),output:(Do,Do,N),kernel:(K,K,M),FLOPS =  Do× Do× M × N × K × K\n",
    "\n",
    "# 该方法卷积 FLOPS = (Do× Do× M × N × K × K)/P + (Do× Do× N) ×（M −M/P）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c048c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch\n",
    "!pip install torch==1.7.0\n",
    "# Install MMCV\n",
    "!pip install mmcv-full==1.3.18 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html\n",
    "#install mmcv  mmcv的版本要修改\n",
    "!git clone https://github.com/open-mmlab/mmclassification.git\n",
    "%cd mmclassification\n",
    "!pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from mmcv.cnn.bricks.registry import CONV_LAYERS\n",
    "import numpy as np\n",
    "import os\n",
    "import torch, torchvision\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "from mmcls.datasets.builder import DATASETS\n",
    "from mmcls.datasets import BaseDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from mmcls.apis import train_model,inference_model,show_result_pyplot\n",
    "from mmcls.datasets import build_dataset\n",
    "from mmcls.models import build_classifier\n",
    "from mmcls.apis import set_random_seed\n",
    "from mmcls.models import BACKBONES\n",
    "from mmcv.cnn import build_conv_layer, build_norm_layer\n",
    "from mmcls.models.backbones.resnet import ResLayer, ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed7c540",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CONV_LAYERS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4078fae20ca4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#卷积模块\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mCONV_LAYERS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHetConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     def __init__(self,input_channel,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CONV_LAYERS' is not defined"
     ]
    }
   ],
   "source": [
    "#卷积模块\n",
    "@CONV_LAYERS.register_module()\n",
    "class HetConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_channel,\n",
    "                 output_channel,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True,\n",
    "                 p=4,\n",
    "                 **kwargs):\n",
    "        super(HetConv2d,self).__init__(**kwargs)\n",
    "        assert output_channel%p == 0 and input_channel%p ==0\n",
    "        \n",
    "        self.conv3_3 = nn.Conv2d(input_channel,output_channel,kernel_size,padding =1,groups=p)\n",
    "        self.conv1_1 = nn.Conv2d(input_channel,output_channel,1,stride=1,padding =0)\n",
    "        self.conv1_1_ = nn.Conv2d(input_channel,output_channel,1,stride=1,groups = p,padding =0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #1*1可能让结果变大，要用padding=0\n",
    "        return self.conv3_3(x)+self.conv1_1(x)-self.conv1_1_(x)\n",
    "    \n",
    "\n",
    "#真正的实现\n",
    "\n",
    "class HetConv(nn.Module):\n",
    "    '''\n",
    "    将卷积操作拆分成一层一层的执行，再相加，用两个for循环完整卷积操作，就能够实现对于其中通道卷积的修改\n",
    "    '''\n",
    "    def __init__(self,in_channels,\n",
    "                    out_channels,\n",
    "                    p):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels= out_channels\n",
    "        self.p = p\n",
    "        self.weights= nn.ModuleList()\n",
    "        for i in range(self.out_channels):\n",
    "            self.weights.append(self.make_one_wegiht(i,p))\n",
    "    \n",
    "    def make_one_wegiht(self,n,p):\n",
    "        weight = nn.ModuleList()\n",
    "        for i in range(self.in_channels):\n",
    "            if ((i-n)%p==0):\n",
    "                weight.append(nn.Conv2d(1,1,3,1,1))\n",
    "            else:\n",
    "                weight.append(nn.Conv2d(1,1,1,1,0))\n",
    "        return weight\n",
    "    def forward(self,x):\n",
    "        out = []\n",
    "        for i in range(self.out_channels):\n",
    "            out_ = self.weights[i][0](x[:,0:1,:,:])\n",
    "            for j in range(1,self.in_channels):\n",
    "                out_ +=self.weights[i][j](x[:,j:j+1,:,:])\n",
    "            out.append(out_)\n",
    "        return torch.cat(out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21df817",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-00c849c78b8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#使用上面的卷积做一个基础模块，这个是3*3+3*3，名字不能改\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#有坑：expansion表示中间是扩大还是缩小的比率，BasicBlock=1 ，Bottleneck =4,如果模型继承了resnet就要确定这个值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mBasicBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     def __init__(self,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#使用上面的卷积做一个基础模块，这个是3*3+3*3，名字不能改\n",
    "#有坑：expansion表示中间是扩大还是缩小的比率，BasicBlock=1 ，Bottleneck =4,如果模型继承了resnet就要确定这个值\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 p=4,\n",
    "                 expansion=1,\n",
    "                 stride=1,\n",
    "                 dilation=1,\n",
    "                 downsample=None,\n",
    "                 style='pytorch',\n",
    "                 with_cp=False,\n",
    "                 conv_cfg=dict(type='HetConv2d'),\n",
    "                 norm_cfg=dict(type='BN')):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.expansion = expansion\n",
    "        assert self.expansion == 1\n",
    "        assert out_channels % expansion == 0\n",
    "        self.mid_channels = out_channels // expansion\n",
    "        assert in_channels % p ==0 and out_channels % p ==0\n",
    "        self.mid_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.style = style\n",
    "        self.with_cp = with_cp\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "\n",
    "        self.norm1_name, norm1 = build_norm_layer(\n",
    "            norm_cfg, self.mid_channels, postfix=1)\n",
    "        self.norm2_name, norm2 = build_norm_layer(\n",
    "            norm_cfg, out_channels, postfix=2)\n",
    "\n",
    "        self.conv1 = build_conv_layer(\n",
    "            conv_cfg,\n",
    "            in_channels,\n",
    "            self.mid_channels,\n",
    "            3,\n",
    "            stride=stride,\n",
    "            padding=dilation,\n",
    "            dilation=dilation,\n",
    "            bias=False)\n",
    "        self.add_module(self.norm1_name, norm1)\n",
    "        self.conv2 = build_conv_layer(\n",
    "            conv_cfg,\n",
    "            self.mid_channels,\n",
    "            out_channels,\n",
    "            3,\n",
    "            padding=1,\n",
    "            bias=False)\n",
    "        self.add_module(self.norm2_name, norm2)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    @property\n",
    "    def norm1(self):\n",
    "        return getattr(self, self.norm1_name)\n",
    "\n",
    "    @property\n",
    "    def norm2(self):\n",
    "        return getattr(self, self.norm2_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        def _inner_forward(x):\n",
    "            identity = x\n",
    "\n",
    "            out = self.conv1(x)\n",
    "            out = self.norm1(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "            out = self.conv2(out)\n",
    "            out = self.norm2(out)\n",
    "\n",
    "            if self.downsample is not None:\n",
    "                identity = self.downsample(x)\n",
    "\n",
    "            out += identity\n",
    "\n",
    "            return out\n",
    "\n",
    "        if self.with_cp and x.requires_grad:\n",
    "            out = cp.checkpoint(_inner_forward, x)\n",
    "        else:\n",
    "            out = _inner_forward(x)\n",
    "\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97758941",
   "metadata": {},
   "outputs": [],
   "source": [
    "@BACKBONES.register_module()\n",
    "class HetResNet(ResNet):\n",
    "    arch_settings = {\n",
    "        50: (BasicBlock, (3, 4, 6, 3)),\n",
    "        101: (BasicBlock, (3, 4, 23, 3)),\n",
    "        152: (BasicBlock, (3, 8, 36, 3))}\n",
    "\n",
    "    def __init__(self, depth,**kwargs):\n",
    "        super(HetResNet, self).__init__(depth,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2aad96d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-baadccf37ec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvalid_data_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/kaggle/input/10-monkey-species/validation/validation/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#将数据集写入文本中，方便解析\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#数据路径\n",
    "training_data_path='/kaggle/input/10-monkey-species/training/training/'\n",
    "valid_data_path='/kaggle/input/10-monkey-species/validation/validation/'\n",
    "#将数据集写入文本中，方便解析\n",
    "label=os.listdir(training_data_path)\n",
    "with open('train.txt','w') as f:\n",
    "    for l in range(len(label)):\n",
    "        for filename in os.listdir(os.path.join(training_data_path,label[l])):\n",
    "            line=f'{label[l]}/{filename} {l}\\n'\n",
    "            f.write(line)\n",
    "with open('valid.txt','w') as f:\n",
    "    for l in range(len(label)):\n",
    "        for filename in os.listdir(os.path.join(valid_data_path,label[l])):\n",
    "            line=f'{label[l]}/{filename} {l}\\n'\n",
    "            f.write(line)#重写数据类，可以将类名加入，也可以不加\n",
    "#构造数据集，使用BaseDataset作为基类，子类只要实现load_annotations生成[{'img':path,'label':1,'other':data}]格式的数据即可,但是注意字典的\n",
    "#key以匹配pipeline中的使用\n",
    "@DATASETS.register_module()\n",
    "class MyDataset(BaseDataset):\n",
    "    def load_annotations(self):\n",
    "        assert isinstance(self.ann_file, str)\n",
    "        data_infos = []\n",
    "        with open(self.ann_file) as f:\n",
    "            samples = [x.strip().split(' ') for x in f.readlines()]\n",
    "            for filename, gt_label in samples:\n",
    "                #里面的key是固定要，要匹配LOADPIPELINE中的key\n",
    "                info = {'img_prefix': self.data_prefix}\n",
    "                info['img_info'] = {'filename': filename}\n",
    "                info['gt_label'] = np.array(gt_label, dtype=np.int64)\n",
    "                data_infos.append(info)\n",
    "            return data_infos\n",
    "#自定义类增益的方法\n",
    "from mmcls.datasets import PIPELINES\n",
    "\n",
    "#输入的是字典\n",
    "@PIPELINES.register_module()\n",
    "class MyTransform(object):\n",
    "    def __call__(self, results):\n",
    "        results['dummy'] = True\n",
    "        # apply transforms on results['img']\n",
    "        return results\n",
    "    \n",
    "\n",
    "img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),#读取完成后就变成了np矩阵了\n",
    "    dict(type='RandomResizedCrop', size=224),#都是用Mmcv中对矩阵的操作实现的\n",
    "    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
    "    dict(type='ToPIL'),\n",
    "    dict(type='MyTransform'),#如果要随意增益，是针对PIL图，所以前面后面是固定格式\n",
    "    dict(type='ToNumpy'),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='ImageToTensor', keys=['img']),# to_tensor(img.transpose(2, 0, 1))变换通道后变为张量，这个没有[0，1]的归一化\n",
    "    dict(type='ToTensor', keys=['gt_label']),#直接变为张量\n",
    "    dict(type='Collect', keys=['img', 'gt_label'])\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='Resize', size=256),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='ImageToTensor', keys=['img']),\n",
    "    dict(type='Collect', keys=['img'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df071f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ff73b27134ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#读取所有的参数,参数文件就在当下文件夹中\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./configs/resnet/resnet50_8xb16_cifar10.py'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(f'Config:\\n{cfg.pretty_text}')  #输出所有的参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "#读取所有的参数,参数文件就在当下文件夹中\n",
    "cfg = Config.fromfile('./configs/resnet/resnet50_8xb16_cifar10.py')\n",
    "#print(f'Config:\\n{cfg.pretty_text}')  #输出所有的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85d7e5b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-591f031a06b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#数据集参数指定,对其进行修改\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MyDataset'\u001b[0m \u001b[1;31m#字符串就是数据类\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MyDataset'\u001b[0m\u001b[1;31m#数据类名，这个是构建数据集的参数字典\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "#数据集参数指定,对其进行修改\n",
    "cfg.dataset_type = 'MyDataset' #字符串就是数据类\n",
    "\n",
    "\n",
    "cfg.data.train.type = 'MyDataset'#数据类名，这个是构建数据集的参数字典\n",
    "cfg.data.train.ann_file = '/kaggle/working/mmclassification/train.txt'#文本文件\n",
    "cfg.data.train.data_prefix = training_data_path#路径前缀\n",
    "\n",
    "cfg.data.train.pipeline=[dict(type='LoadImageFromFile'),\n",
    "            dict(type='RandomResizedCrop', size=224, backend='pillow'),\n",
    "            dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
    "            dict(type='Normalize',\n",
    "                mean=[110.508858/255.0, 109.552668/255.0,84.623747/255.0],\n",
    "                std=[67.212821/255.0,66.229520/255.0, 66.544232/255.0],\n",
    "                to_rgb=True),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='ToTensor', keys=['gt_label']),\n",
    "            dict(type='Collect', keys=['img', 'gt_label'])]\n",
    "\n",
    "\n",
    "cfg.data.val.type = 'MyDataset'\n",
    "cfg.data.val.ann_file = '/kaggle/working/mmclassification/valid.txt'\n",
    "cfg.data.val.data_prefix = valid_data_path\n",
    "cfg.data.val.pipeline=[dict(type='LoadImageFromFile'),\n",
    "            dict(type='Resize', size=(256, -1)),\n",
    "            dict(type='CenterCrop', crop_size=224),\n",
    "            dict(type='Normalize',\n",
    "                mean=[110.508858/255.0, 109.552668/255.0,84.623747/255.0],\n",
    "                std=[67.212821/255.0,66.229520/255.0, 66.544232/255.0],\n",
    "                to_rgb=True),\n",
    "            dict(type='ToTensor', keys=['gt_label']),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img','gt_label'])]\n",
    "# modify num classes of the model in box head\n",
    "cfg.model.head.num_classes = 10#预测类个数\n",
    "cfg.model.backbone.type ='HetResNet'\n",
    "cfg.model.head.in_channels = 512\n",
    "#cfg.model.backbone.expansion=1\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "#cfg.load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'   #是否是预训练模型\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "#cfg.work_dir = './tutorial_exps'  #保存路径\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer = dict(type='Adam', lr=0.1, weight_decay=1e-4)  #学习率设置\n",
    "\n",
    "\n",
    "\n",
    "#学习率调整  参数一定要传对\n",
    "cfg.lr_config = dict(policy='step',0.1, step=[30,90])\n",
    "#cfg.lr_config = dict(policy='exp',gamma=0.1)\n",
    "#cfg.lr_config = dict(policy='fixed')\n",
    "#cfg.lr_config = dict(policy='poly',power=1.25, min_lr=0.001)\n",
    "#cfg.lr_config=dict(policy='CosineAnnealing',min_lr=0.0001)\n",
    "#cfg.lr_config = dict(policy='CosineRestart',periods=[1,3])\n",
    " \n",
    "cfg.lr_config.warmup='linear'\n",
    "cfg.lr_config.warmup_iters=500\n",
    "cfg.lr_config.warmup_ratio=0.001\n",
    "\n",
    "\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=100) #训练迭代次数\n",
    "\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)#设备指定\n",
    "cfg.evaluation =  dict(interval=1, metric='accuracy')\n",
    "cfg.evaluation.interval = 12\n",
    "cfg.workflow= [('train', 2), ('val', 1)]# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')  #输出所有的参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2a123b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmcv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8fe299734002>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#执行训练过程\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m from mmcv.cnn import (ConvModule, build_conv_layer, build_norm_layer,\n\u001b[0m\u001b[0;32m      3\u001b[0m                       constant_init, kaiming_init)\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#构造数据集，它的长度len(data_loaders) == len(workflow)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#datasets = [build_dataset(cfg.data.train)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mmcv'"
     ]
    }
   ],
   "source": [
    "#执行训练过程\n",
    "from mmcv.cnn import (ConvModule, build_conv_layer, build_norm_layer,\n",
    "                      constant_init, kaiming_init)\n",
    "#构造数据集，它的长度len(data_loaders) == len(workflow)\n",
    "#datasets = [build_dataset(cfg.data.train)]\n",
    "datasets = [build_dataset(cfg.data.train),build_dataset(cfg.data.val)]\n",
    "# Build the detector\n",
    "model = build_classifier(cfg.model) #建立模型\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES#将类名加入到模型中\n",
    "\n",
    "# Create work_dir\n",
    "\n",
    "#data_loader可以进行优化，\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))#创建保存文件\n",
    "train_model(model, \n",
    "            datasets, \n",
    "            cfg, \n",
    "            distributed=False,\n",
    "            validate=True) #训练validate=True是用来做eval的钩子的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "045e9671",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmcls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b9728c94f6a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#小技巧：给类添加方法\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmmcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifiers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward_dummy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneck\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mmcls'"
     ]
    }
   ],
   "source": [
    "#小技巧：给类添加方法\n",
    "from mmcls.models.classifiers import ImageClassifier\n",
    "def forward_dummy(self,x):\n",
    "    x = self.extract_feat(x)\n",
    "    x =self.head.simple_test(x)\n",
    "    return x\n",
    "ImageClassifier.forward_dummy = forward_dummy\n",
    "\n",
    "forward=model.forward\n",
    "model.forward=model.forward_dummy\n",
    "\n",
    "#计算每一层的FLOPS\n",
    "from mmcv.cnn.utils import get_model_complexity_info\n",
    "#查看函数支持计算的层有哪些\n",
    "#model.forward = model.forward_dummy\n",
    "#需要对HEADs里实现 extra_repr,随便输出什么字符串即可\n",
    "get_model_complexity_info(model,(3,512,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d00c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
