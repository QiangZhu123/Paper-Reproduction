{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387f59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f11f8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    CBAM:Convolutional Blck Attention Module\n",
    "    \n",
    "    Args:\n",
    "        in_channel(int):channel number of input feature\n",
    "        ratio(int):linear Layer\n",
    "    Return:\n",
    "        out (tensor):channel attention ,the shape is (N,1,H,W)\n",
    "    \"\"\"\n",
    "    def __init__(self,in_channel,ratio = 16):\n",
    "        super(ChannelAttention,self).__init__()\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.linear = nn.Sequential(nn.Conv2d(in_channel,in_channel//ratio,1,bias=False),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Conv2d(in_channel//ratio,in_channel,1,bias=False)\n",
    "        )\n",
    "        self.act = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        avg = self.linear(self.avg_pool(x))\n",
    "        maxs = self.linear(self.max_pool(x))\n",
    "        out = avg + maxs\n",
    "        return self.act(out)\n",
    "        \n",
    "class SpatialAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2,1,kernel_size,padding = kernel_size//2)\n",
    "        self.act = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        avg = torch.mean(x,dim=1,keepdim=True)\n",
    "        maxs,_ = torch.max(x,dim=1,keepdim=True)\n",
    "        att = self.conv(torch.cat([avg,maxs],dim=1))\n",
    "        return self.act(att)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990d3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBAM(nn.Module):\n",
    "    \"\"\"\n",
    "    put the channel and spatial block at the end of basic 3*3 block\n",
    "    \"\"\"\n",
    "    def __init__(self,in_channel,\n",
    "                planes,\n",
    "                downsample=False):\n",
    "        super(CBAM,self).__init__()\n",
    "        self.in_channel= in_channel\n",
    "        self.planes =planes \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channel,planes,3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "        self.conv2 =nn.Conv2d(planes,planes,3,stride=1,padding=1)\n",
    "        self.bn2=nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.donwsample = downsample\n",
    "        \n",
    "        self.channel =ChannelAttention(planes)\n",
    "        self.spatial=SpatialAttention()\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        \n",
    "        out =self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out =self.act(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out =self.bn2(out)\n",
    "        \n",
    "        out = self.channel(out)*out\n",
    "        out =self.spatial(out)*out\n",
    "        \n",
    "        if self.donwsample:\n",
    "            residual =self.donwsample(residual)\n",
    "        \n",
    "        out += residual\n",
    "        \n",
    "        return self.act(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d092525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CBAM(64,64)\n",
    "a =torch.randn(1,64,10,10)\n",
    "torch.onnx.export(test,a,'mo.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2353ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9959e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
