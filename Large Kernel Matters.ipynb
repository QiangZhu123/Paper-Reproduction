{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55db1643",
   "metadata": {},
   "source": [
    "\n",
    "!pip install mmcv-full==1.3.18 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html\n",
    "#install mmcv  mmcv的版本要修改\n",
    "!rm  -rf  mmsegmentation\n",
    "!git  clone  https://github.com/open-mmlab/mmsegmentation.git \n",
    "%cd  mmsegmentation\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067e2052",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bbae4352f606>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import  torch.nn.functional as F\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404aadfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据的参数文件,随便找一个文件参数\n",
    "from mmcv import Config\n",
    "cfg = Config.fromfile('configs/pspnet/pspnet_r50-d8_512x1024_40k_cityscapes.py')\n",
    "#print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#仔细修改各个部分的参数\n",
    "\n",
    "# Since we use ony one GPU, BN is used instead of SyncBN 模型参数，保证模型中的BN层都是一样的\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg\n",
    "\n",
    "\n",
    "cfg.model.pop('auxiliary_head')\n",
    "cfg.model.backbone=dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(0,1,2,3 ),\n",
    "        strides= (1,2,2,2,),\n",
    "        style='pytorch')\n",
    "cfg.model.pretrained =None\n",
    "#根据自己模型需要的参数给定，但是要注意继承基类需要的参数也要给定，不然还是修改其内部函数\n",
    "cfg.model.decode_head = dict(type='GCNHead',\n",
    "                             out_channels=21,\n",
    "                             kernel_size=3,\n",
    "                             input_channels = [256,512,1024,2048],\n",
    "                            in_index=3,\n",
    "                            channels=256,\n",
    "                            num_classes=21,\n",
    "                            norm_cfg=cfg.norm_cfg,\n",
    "                            align_corners=False,\n",
    "                            loss_decode=dict(\n",
    "                            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0))\n",
    "\n",
    "#注意模型的一下参数到底是要放在什么位置上的\n",
    "cfg.train_cfg = cfg.model.train_cfg\n",
    "cfg.test_cfg =cfg.model.test_cfg\n",
    "cfg.model.pop('train_cfg')\n",
    "cfg.model.pop('test_cfg')\n",
    "\n",
    "#GPU\n",
    "cfg.gpu_ids = range(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self,in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size):\n",
    "        super(GCN,self).__init__()\n",
    "        self.conv1_1=nn.Conv2d(in_channels,out_channels,(kernel_size,1),padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(out_channels,out_channels,(1,kernel_size))\n",
    "    \n",
    "        self.conv2_1 = nn.Conv2d(in_channels,out_channels,(1,kernel_size),padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(out_channels,out_channels,(kernel_size,1))\n",
    "\n",
    "        self.init_weights()\n",
    "    def forward(self,x):\n",
    "        out = self.conv1_2(self.conv1_1(x))\n",
    "        out += self.conv2_2(self.conv2_1(x))\n",
    "        return out\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal(m.weight)\n",
    "                \n",
    "class BRModule(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channes,\n",
    "                out_channels,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channes,out_channels,3,padding=1)\n",
    "        self.relu =nn.ReLU(True)\n",
    "        self.conv2 = nn.Conv2d(in_channes,out_channels,3,padding=1)\n",
    "        self.init_weights()\n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        x =self.conv1(x)\n",
    "        x= self.relu(x)\n",
    "        x= self.conv2(x)\n",
    "        x +=residual\n",
    "        return x\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels,kernel_size):\n",
    "        super().__init__()\n",
    "        self.gcn = GCN(in_channels,out_channels,kernel_size)\n",
    "        self.bn=BRModule(out_channels,out_channels)\n",
    "    def forward(self,x):\n",
    "        x =self.gcn(x)\n",
    "        x =self.bn(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b8dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.models.builder import HEADS\n",
    "from mmseg.models.decode_heads.decode_head import BaseDecodeHead\n",
    "\n",
    "#修改需要使用这个重新注册\n",
    "HEADS.module_dict.pop('GCNHead')\n",
    "@HEADS.register_module()\n",
    "class GCNHead(BaseDecodeHead):\n",
    "    \n",
    "    def __init__(self,input_channels,out_channels,kernel_size,**kwargs):\n",
    "        super(GCNHead,self).__init__(input_channels,**kwargs)#参数传给基类\n",
    "        \n",
    "        #这里要注意，一定要把模块使用这种形式，不然无法注册到模型中去\n",
    "        #或者使用列表[]，再用nn.Sequential(**list)的形式，不过这个是针对序列模型\n",
    "        self.gcn_layer = nn.ModuleList()\n",
    "        self.deconv_layer =nn.ModuleList()\n",
    "        \n",
    "        for i in range(len(input_channels)):\n",
    "            self.gcn_layer.append(GCNLayer(input_channels[i],out_channels,kernel_size))\n",
    "            self.deconv_layer.append(nn.ConvTranspose2d(out_channels,out_channels,2,2))\n",
    "            \n",
    "        #这里也是注册到模型中\n",
    "        self.br_layer = nn.ModuleList()\n",
    "        for _ in range(len(input_channels)-1):\n",
    "            self.br_layer.append(BRModule(out_channels,out_channels))\n",
    "        self.br1 = BRModule(out_channels,out_channels)\n",
    "        self.br2 = BRModule(out_channels,out_channels)\n",
    "        self.deconv =nn.ConvTranspose2d(out_channels,out_channels,2,2)\n",
    "    def forward(self,out):\n",
    "        x = self.deconv_layer[-1](self.gcn_layer[-1](out[-1]))\n",
    "        \n",
    "        for i in reversed(range(len(out)-1)):\n",
    "            x +=self.gcn_layer[i](out[i])\n",
    "            \n",
    "            x =self.br_layer[i](x)\n",
    "            x =self.deconv_layer[i](x)\n",
    "        x =self.br1(x)\n",
    "        x =self.deconv(x)\n",
    "        x =self.br2(x)\n",
    "        return x\n",
    "    def _init_inputs(self, in_channels, in_index, input_transform=None):\n",
    "        pass\n",
    "    \n",
    "    def extra_repr(self):\n",
    "        s = f\"GCNHEAD\"\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7004269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "from mmseg.models.backbones.resnet import ResNet\n",
    "from mmseg.models.builder import BACKBONES\n",
    "# Build the detector\n",
    "model = build_segmentor(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#测试模型\n",
    "device =torch.device('cuda:0')\n",
    "test =torch.randn(1,3,512,512).to(device)\n",
    "print(test.device)\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward = model.forward\n",
    "model.forward = model.forward_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ccbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算每一层的FLOPS\n",
    "from mmcv.cnn.utils import get_model_complexity_info\n",
    "#查看函数支持计算的层有哪些\n",
    "#model.forward = model.forward_dummy\n",
    "#需要对HEADs里实现 extra_repr,随便输出什么字符串即可\n",
    "get_model_complexity_info(model,(3,512,512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e0a36",
   "metadata": {},
   "source": [
    "# 数据集参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df69b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify dataset type and path数据集的参数的预先设定\n",
    "cfg.dataset_type = 'StandfordBackgroundDataset'\n",
    "cfg.data_root = data_root\n",
    "cfg.train_cfg = dict()\n",
    "cfg.test_cfg = dict(mode='whole')\n",
    "\n",
    "#batch大小\n",
    "cfg.data.samples_per_gpu = 8\n",
    "cfg.data.workers_per_gpu=8\n",
    "#标准化参数，要计算的\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "\n",
    "cfg.crop_size = (256, 256)\n",
    "#数据处理方式\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(320, 240), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(320, 240),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "#数据集，需要加入label路径\n",
    "#类名\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "#参数\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = img_dir\n",
    "cfg.data.train.ann_dir = ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = '/kaggle/working/mmsegmentation/mmsegmentation/splits/train.txt' \n",
    "\n",
    "#类名\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "#参数\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = '/kaggle/working/mmsegmentation/mmsegmentation/splits/val.txt'\n",
    "\n",
    "#类名\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "#参数\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch模型参数下载\n",
    "#cfg.load_from = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.保存路径\n",
    "cfg.work_dir = './work_dirs/tutorial'\n",
    "#这个是配合val\n",
    "cfg.evaluation = dict(interval=1, metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac9b41",
   "metadata": {},
   "source": [
    "# 训练设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166251dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
    "cfg.dist_params = dict(backend='nccl')\n",
    "cfg.log_level = 'INFO'\n",
    "cfg.load_from = None\n",
    "cfg.resume_from = None\n",
    "\n",
    "\n",
    "cfg.workflow = [('train', 1)]\n",
    "cfg.cudnn_benchmark = True\n",
    "\n",
    "#momentum，weight_decay参数设置\n",
    "cfg.optimizer = dict(type='SGD', lr=0.004, momentum=0.9, weight_decay=0.0001)\n",
    "cfg.optimizer_config = dict()\n",
    "#学习率变化\n",
    "cfg.lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n",
    "#训练器\n",
    "cfg.runner = dict(type='IterBasedRunner', max_iters=40000)\n",
    "#保存模型\n",
    "cfg.checkpoint_config = dict(by_epoch=False, interval=4000)\n",
    "#评估方法\n",
    "cfg.evaluation = dict(interval=4000, metric='mIoU', pre_eval=True)\n",
    "#继续训练\n",
    "cfg.load_from = 'checkpoints/pspnet_r50-d8_512x1024_40k_cityscapes_20200605_003338-2966598c.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.保存路径\n",
    "cfg.work_dir = './work_dirs/tutorial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e30765",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6771f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset，\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n",
    "# Add an attribute for visualization convenience 这里就是用到训练集的标签信息\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=False, \n",
    "                meta=dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55634a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
